import type { AwsService } from './types'

export const DATABASE_SERVICES: AwsService[] = [
  {
    id: 'rds',
    name: 'RDS',
    fullName: 'Relational Database Service',
    cat: 'database',
    level: 'beginner',
    icon: '\u{1F418}',
    short: 'Managed SQL databases. Pick your engine (PostgreSQL, MySQL, etc.) and AWS handles backups, patching, scaling, and replication.',
    analogy: 'Hiring a property manager for your database apartment \u2014 they handle maintenance, you just live there.',
    detail: 'RDS lets you spin up a database in minutes without thinking about the server it runs on. You choose an engine (PostgreSQL, MySQL, MariaDB, Oracle, SQL Server, or Aurora), pick the size, and AWS handles everything else: automated backups, security patches, failover, and read replicas.',
    useCases: [
      'Any app that needs a traditional SQL database',
      'E-commerce product catalogs',
      'User accounts and authentication data',
    ],
    keyTerms: {
      Engine: 'The database type (PostgreSQL, MySQL, etc.)',
      'Multi-AZ': 'Automatic failover to a backup in another data center',
      'Read Replica': 'A read-only copy to spread out database load',
    },
    pricing: 'Free tier: 750 hrs/month of db.t3.micro for 12 months. After: varies by instance size and engine.',
    code: '// Connect to RDS PostgreSQL from Node.js\nimport pg from \'pg\';\n\nconst pool = new pg.Pool({\n  host: \'mydb.abc123.us-east-1.rds.amazonaws.com\',\n  database: \'myapp\',\n  user: \'admin\',\n  password: process.env.DB_PASSWORD,\n});\n\nconst { rows } = await pool.query(\'SELECT * FROM users\');',
  },
  {
    id: 'dynamodb',
    name: 'DynamoDB',
    fullName: 'Amazon DynamoDB',
    cat: 'database',
    level: 'intermediate',
    icon: '\u26A1',
    short: 'A blazing-fast NoSQL database. No schemas, no SQL. Just key-value pairs and documents with single-digit millisecond reads.',
    analogy: 'A massive dictionary \u2014 look up any word (key) instantly, no need to read the whole book.',
    detail: 'DynamoDB is a fully managed NoSQL database that scales to handle millions of requests per second. You define a table with a primary key, and DynamoDB handles all partitioning and replication. It\'s schema-less, so each item can have different attributes. Think of it as a turbocharged JSON store.',
    useCases: [
      'Session storage',
      'Real-time leaderboards',
      'IoT device data',
      'Shopping carts and user preferences',
    ],
    keyTerms: {
      'Partition Key': 'The primary lookup key for your data',
      'Sort Key': 'Optional secondary key for ordering/querying within a partition',
      GSI: 'Global Secondary Index \u2014 an alternate way to query your data',
    },
    pricing: 'Free tier: 25 GB storage + 25 read/write capacity units (forever, not 12 months!).',
    code: '// Write to DynamoDB\nimport { DynamoDBClient, PutItemCommand } from \'@aws-sdk/client-dynamodb\';\n\nawait client.send(new PutItemCommand({\n  TableName: \'Users\',\n  Item: {\n    userId: { S: \'u_123\' },\n    name: { S: \'Alice\' },\n    score: { N: \'42\' },\n  },\n}));',
  },
  {
    id: 'aurora',
    name: 'Aurora',
    fullName: 'Amazon Aurora',
    cat: 'database',
    level: 'intermediate',
    icon: '\u{1F30C}',
    short: 'AWS\'s own high-performance SQL database. Compatible with MySQL/PostgreSQL but 3\u20135x faster, with automatic scaling and replication.',
    analogy: 'A souped-up sports car engine that drops right into your regular car. Same gas (SQL), way more horsepower.',
    detail: 'Aurora is AWS\'s custom-built relational database that\'s fully compatible with MySQL and PostgreSQL. It uses a distributed storage layer that automatically replicates data across 3 Availability Zones. Aurora Serverless can even scale capacity up and down automatically.',
    useCases: [
      'High-traffic production applications',
      'Applications that outgrow standard RDS',
      'SaaS platforms needing high availability',
    ],
    keyTerms: {
      'Aurora Serverless': 'Automatically scales compute capacity based on demand',
      Cluster: 'A group of database instances that share the same storage',
    },
    pricing: 'No free tier. Starts at ~$0.10/hr for the smallest instance. Aurora Serverless v2 scales from $0.12/ACU-hour.',
  },
  {
    id: 'elasticache',
    name: 'ElastiCache',
    fullName: 'Amazon ElastiCache',
    cat: 'database',
    level: 'intermediate',
    icon: '\u{1F3CE}\uFE0F',
    short: 'Managed Redis or Memcached. An in-memory cache that makes your app\'s frequent database queries lightning fast.',
    analogy: 'Sticky notes on your desk \u2014 instead of walking to the filing cabinet (database) every time, you keep hot info within arm\'s reach.',
    detail: 'ElastiCache puts a fast, in-memory data store between your app and your database. When your app asks for data, it checks the cache first. If it\'s there (a "cache hit"), it\'s returned in microseconds instead of milliseconds. This dramatically reduces database load and speeds up response times.',
    useCases: [
      'Caching database query results',
      'Session storage',
      'Real-time leaderboards and counters',
      'Rate limiting',
    ],
    keyTerms: {
      Redis: 'Feature-rich in-memory store with data structures, pub/sub, persistence',
      Memcached: 'Simpler, multi-threaded cache (less features, more raw throughput)',
      TTL: 'Time To Live \u2014 how long a cached item stays before expiring',
    },
    pricing: 'Free tier: 750 hrs of cache.t3.micro for 12 months. After: varies by node type.',
  },
  {
    id: 'documentdb',
    name: 'DocumentDB',
    fullName: 'Amazon DocumentDB',
    cat: 'database',
    level: 'intermediate',
    icon: '\u{1F343}',
    short: 'Managed MongoDB-compatible database. If you love MongoDB\'s document model but want AWS to handle the operations.',
    analogy: 'A MongoDB that someone else maintains for you \u2014 same language, managed infrastructure.',
    detail: 'DocumentDB is a managed document database with MongoDB compatibility. You can use your existing MongoDB drivers and tools, but AWS manages backups, scaling, and replication. Under the hood it uses a different storage engine than MongoDB, so there are some compatibility nuances.',
    useCases: [
      'Applications already using MongoDB',
      'Content management with flexible schemas',
      'Catalogs and user profiles',
    ],
    keyTerms: {
      Document: 'A JSON-like data record',
      Collection: 'A group of documents (like a SQL table)',
    },
    pricing: 'No free tier. Instances start at ~$0.076/hr for db.t3.medium.',
  },
  {
    id: 'redshift',
    name: 'Redshift',
    fullName: 'Amazon Redshift',
    cat: 'database',
    level: 'advanced',
    icon: '\u{1F4CA}',
    short: 'A data warehouse for analytics. Run complex SQL queries across petabytes of structured data. Powers business intelligence dashboards.',
    analogy: 'A giant research library organized for answering big questions \u2014 "What were our sales by region last quarter across all products?"',
    detail: 'Redshift is a columnar data warehouse optimized for analytical queries (OLAP). Unlike RDS which handles transactions (many reads/writes per row), Redshift handles analytics (scanning millions of rows, aggregating data). It uses SQL, so it\'s familiar, but the storage and query engine are built for massive-scale analytics.',
    useCases: [
      'Business intelligence dashboards',
      'Sales and revenue analytics',
      'Log analysis at scale',
      'Data lake queries',
    ],
    keyTerms: {
      Cluster: 'A group of nodes that store data and run queries',
      'Columnar Storage': 'Stores data by column rather than row (faster for analytics)',
      'Redshift Serverless': 'Pay-per-query option without managing clusters',
    },
    pricing: 'Serverless: $0.375/RPU-hour. Provisioned: from ~$0.25/hr for dc2.large.',
  },
  {
    id: 'athena',
    name: 'Athena',
    fullName: 'Amazon Athena',
    cat: 'database',
    level: 'intermediate',
    icon: '\u{1F50E}',
    short: 'Query data directly in S3 using SQL. No database to set up \u2014 just point at your files and run queries.',
    analogy: 'A search engine for your files \u2014 ask SQL questions about CSV, JSON, or Parquet files sitting in S3, no database needed.',
    detail: 'Athena is a serverless query engine that lets you run SQL queries directly against data stored in S3. No data loading, no infrastructure to manage. Just create a table definition that maps to your S3 files (CSV, JSON, Parquet, ORC), and start querying. Pay only for the data scanned by each query.',
    useCases: [
      'Ad-hoc analysis of log files in S3',
      'Querying data lake contents',
      'Cost analysis of AWS billing data',
    ],
    keyTerms: {
      'External Table': 'A table definition that points to S3 data',
      Partition: 'Organizing data by date/category to speed queries and reduce cost',
    },
    pricing: '$5 per TB of data scanned. Use columnar formats (Parquet) to dramatically reduce costs.',
  },
  {
    id: 'opensearch',
    name: 'OpenSearch',
    fullName: 'Amazon OpenSearch Service',
    cat: 'database',
    level: 'advanced',
    icon: '\u{1F50D}',
    short: 'Managed Elasticsearch/OpenSearch. Full-text search, log analytics, and real-time application monitoring at scale.',
    analogy: 'The search engine behind your search bar \u2014 indexes your data so users can find anything in milliseconds.',
    detail: 'OpenSearch (formerly Elasticsearch Service) provides managed search and analytics. It excels at full-text search, log analytics, and real-time monitoring. You ingest data from your application or logs, OpenSearch indexes it, and you can search and visualize it with dashboards (OpenSearch Dashboards, formerly Kibana).',
    useCases: [
      'Full-text search for your application',
      'Centralized log analytics (ELK stack)',
      'Real-time application monitoring',
    ],
    keyTerms: {
      Index: 'A collection of documents to search',
      Cluster: 'A group of nodes that store and search data',
      'OpenSearch Dashboards': 'Visualization tool (formerly Kibana)',
    },
    pricing: 'No free tier. Starts at ~$0.036/hr for t3.small.search.',
  },
]
