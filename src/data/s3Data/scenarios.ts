import type { Scenario } from './types'

export const SCENARIOS: Scenario[] = [
  {
    id: 'static-site',
    icon: '\u{1F310}',
    label: 'Static Website',
    description: 'HTML, CSS, JS, images served to users',
    title: 'Use S3 Standard + CloudFront',
    body: 'Static websites need instant access and high throughput. Standard is the only sensible choice here. Pair it with CloudFront (AWS CDN) to cache files at edge locations and reduce latency. Set long Cache-Control headers on assets and no-cache on index.html.',
    chips: ['S3 Standard', 'CloudFront CDN', 'Cache-Control headers'],
  },
  {
    id: 'user-uploads',
    icon: '\u{1F4F8}',
    label: 'User Uploads',
    description: 'Profile pics, documents, media files',
    title: 'Start with Standard, Lifecycle to IA',
    body: 'User uploads are accessed frequently right after upload, then taper off. Use Standard for the first 30 days, then a lifecycle rule to move to Standard-IA. For profile pictures that are always visible, keep those in Standard.',
    chips: ['S3 Standard', 'Lifecycle \u2192 Standard-IA', 'Presigned URLs'],
  },
  {
    id: 'log-files',
    icon: '\u{1F4CA}',
    label: 'Log Files',
    description: 'Application logs, analytics events',
    title: 'Intelligent-Tiering or Standard-IA \u2192 Glacier',
    body: 'Logs are write-heavy and rarely read. Intelligent-Tiering handles this perfectly \u2014 it will auto-demote untouched logs. Or use a lifecycle rule: Standard \u2192 IA after 30 days \u2192 Glacier Flexible after 90 days \u2192 delete after 1 year.',
    chips: ['Intelligent-Tiering', 'Lifecycle rules', 'Auto-expiration'],
  },
  {
    id: 'db-backups',
    icon: '\u{1F4BE}',
    label: 'Database Backups',
    description: 'Nightly DB dumps, disaster recovery',
    title: 'Glacier Flexible or Deep Archive',
    body: 'Backups are insurance \u2014 you store them hoping you never need them. Glacier Flexible gives you 3\u20135 hour retrieval when disaster strikes. Deep Archive is cheapest for long-term retention. Use lifecycle rules to auto-transition from Standard after backup completes.',
    chips: ['Glacier Flexible', 'Deep Archive', 'Lifecycle from Standard'],
  },
  {
    id: 'video-media',
    icon: '\u{1F3AC}',
    label: 'Video / Large Media',
    description: 'Video files, podcasts, large assets',
    title: 'Standard + S3 Intelligent-Tiering',
    body: 'New videos get lots of views, then interest drops. Intelligent-Tiering automatically moves cold videos to cheaper tiers without you managing it. For delivery, always use CloudFront in front \u2014 never serve large files directly from S3.',
    chips: ['Intelligent-Tiering', 'CloudFront CDN', 'Transfer Acceleration'],
  },
  {
    id: 'compliance',
    icon: '\u{1F4CB}',
    label: 'Compliance Data',
    description: 'Legal records you must retain for 7+ years',
    title: 'Glacier Deep Archive',
    body: 'This is exactly what Deep Archive was built for. At $0.00099/GB/month, storing 10 TB of compliance records costs about $10/month. The 12\u201348 hour retrieval time is fine because you only access this data during audits or legal proceedings.',
    chips: ['Deep Archive', '$0.00099/GB/mo', '180-day minimum'],
  },
  {
    id: 'unknown',
    icon: '\u{1F937}',
    label: 'I Have No Idea',
    description: 'Unpredictable access patterns',
    title: 'S3 Intelligent-Tiering',
    body: 'This is the "I don\'t want to think about it" class. AWS monitors each object\'s access pattern and moves it between frequent, infrequent, and archive tiers automatically. No retrieval fees, no guesswork. There\'s a small monitoring fee ($0.0025 per 1K objects) but it\'s worth the simplicity.',
    chips: ['Intelligent-Tiering', 'Auto-optimization', 'Zero retrieval fees'],
  },
]
